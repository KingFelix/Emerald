---
date: 2019-10-16
author: jw
title: "Notes from my presentation at the Evans Data dev marketing summit"
description: "How to build developer communities, and why engagement is everything -notes from my talk at the Evans Data Developer Marketing Summit"
categories: [work]
tags: [Developer Marketing]
---
![Emerald](img/Zhu_Jinshi_site_art.png "Art by Zhu Jinshi")
<span class="heroart">A few pieces from one of my favorite artists, <a href="https://www.artsy.net/artist/zhu-jinshi">Zhu Jinshi</a> | <a href="../about#whats-with-the-random-art">What's with the random art?</a></span>


Last month I spoke at the Evans Data Developer Marketing Summit in San Jose. My talk was titled "Building Developer Communities. Why Engagement is Everything". The talk was very well received and I've had multiple requests to turn it into a blog post. The talk centered around why engagement is an important metric to focus on and then walked participants through how we are creating a highly engaged community. 

<h3>Why engagement is everything</h3>
Before I dive in, you need to understand why I'm making the argument that engagement is everything. There are two reasons, first, engagement with your community is how you build trust. Second, engagement is the most cost-efficient way to build awareness on almost every channel. This is because content that has a high engagement rate is organically amplified by the community. 

When you look at a developer program there is a heavy emphasis on content. Product content, learning content, and marketing content. These three content types form the pillars that developer programs are built on. Content is what your community engages with, but creating content is not enough. Content must be served to an audience in a way that catches their attention and pulls them in. 

<h3>Engagement is a journey ... a long one</h3>
When I started at Red Hat, the developer program was just beginning to transition out of its infancy. The team had invested in building most of the key components of the program but had not started building and implementing the processes needed to scale, while maintaining a level of consistency across all of our channels. Because of this, most of the data that I had access to was not trustworthy. 

The story that the data wanted to tell was missing because there was no consistency.

The engagement metrics were all over the board. Some days were grand slams and other days were complete strikeouts. We needed to start testing but before we could trust the data that our tests produced we needed to create a controlled environment that we could benchmark against. Keep in mind that we're talking largely about social channels, so a true control will not exist. To solve for the many factors that go into content creation across all of our social channels, we focused our attention on consistency. 

<h3>Getting to step one</h3>
If I breakdown our process, there would be three main stages that emerge. 
Creating a baseline strategy
Optimizing that strategy
Measuring our way to success
By far, the hardest step is creating a baseline strategy. This is where that sixth sense that you develop after many years of marketing comes in handy. You take everything that you know about your audience and combine it with industry best practices. Once you've done that, come up with some secret sauce that allows you to cut through all of the industry noise. 

In no way is it a scientific or data-driven process, at this stage scientific is not the point. The point is to put your best foot forward and create a level of consistency that you can test against. To accomplish this, we created posting guides for each of our channels that included some basic 'dos and don'ts' along with style/tone guides, posting cadences, and focus topics for each channel.

We gathered about one month of consistent data, which proved to be enough to confidently validate our baseline strategy and progress into our testing and optimization stage. 

<h3>Optimizing our strategy</h3>
Because of the nature of our program, we tend to be more reactive in how and what content we promote. We have to work with the content that we were given. At Red Hat, there is no shortage of upstream projects, products, or topics so our content can be very diverse. On top of that, we don't make a big habit of setting hard delivery dates or assign content pieces to our authors, so most of the time we're working with whatever content falls into our lap that week. 

Since we couldn't depend on consistent topics, post type was the logical starting point for our testing and optimization. For those of you who don't live in the marketing world, post-mix is a very important and easily overlooked component of social engagement. Finding the right post-mix is important for building engaged audiences. A standard mix might include video posts, image posts, link posts, and text posts. We could define these as:

Video post - Any post that has a video embedded
Image post - Any post that has an image uploaded with it
Link post - A text post with an image
Text post - A post that does not have a link, image, or video. This would also include a poll or survey. 

With our data in hand, we spotted some fairly obvious trends. When our post consisted of just over 50% link posts, there was a greater engagement rate. Text posts had some of the highest engagement rates, but when they comprised more than 10% or our post-mix, we begin to see diminishing returns and engagement rates started to drop. 

The more consistent our tests were, the more trends emerged from our data to drive future tests. This is where it can become really difficult.

<h3>Metrics to drive engagement</h3>
The final step here is measuring your strategy. Most people will think this is fairly elementary, but I found that most teams either measure too many things or are not measuring the right things. At Red Hat, I have access to several marketing analytics platforms that generate close to two hundred data points. I would argue that there are maybe fifteen metrics that matter, the rest is just clutter unless you have a very specific question. 

When we talk about metrics we are talking about the data used to evaluate performance. When it comes to engagement there are two dangers with marketing metrics, it's often difficult to identify early indicators, which results in reactive vs responsive strategies. And, the second, is that we forget to factor in how metrics drive employee behavior. 

If our goal is to drive community engagement, focusing heavily on CTR will detract from your ability to achieve that goal. This is because your team will view your communities as a way to drive traffic at the expense of engagement. Additionally, CTR is a trailing indicator, it's what happens after someone has interacted or viewed your content. Liking, sharing, or commenting would be considered a leading indicator. These are subtle differences that define which teams can build engagement.

I hope you've learned something and that the blog is as good as my talk ;) 




